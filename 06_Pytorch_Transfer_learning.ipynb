{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DietzscheNostoevsky/Learning_Pytorch/blob/main/06_Pytorch_Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a computer vision model pretrained on ImageNet and try to leverage its underlying learned representations for classifying images of pizza, steak and sushi."
      ],
      "metadata": {
        "id": "KfWbRH_sntfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Setup \n"
      ],
      "metadata": {
        "id": "-gzMrEgNt00t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required modules and files.  \n",
        "Using going_modular directory functions.  \n",
        "\n"
      ],
      "metadata": {
        "id": "ndxasTW0t46N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE1nrMZnvYAX",
        "outputId": "398c3e20-4277-4545-f5a6-4b0b015467e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "torch version: 2.0.1+cu118\n",
            "torchvision version: 0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi7D9Ve3v6ah",
        "outputId": "faf52a30-6ea2-4efc-ebe6-93ffdd2daf19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 3768, done.\u001b[K\n",
            "remote: Counting objects: 100% (390/390), done.\u001b[K\n",
            "remote: Compressing objects: 100% (216/216), done.\u001b[K\n",
            "remote: Total 3768 (delta 209), reused 322 (delta 169), pack-reused 3378\u001b[K\n",
            "Receiving objects: 100% (3768/3768), 648.93 MiB | 39.65 MiB/s, done.\n",
            "Resolving deltas: 100% (2165/2165), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device Agnostic Code \n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "cWWKTUuVxiRk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Getting Data "
      ],
      "metadata": {
        "id": "zwxidou5yG5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import zipfile \n",
        "from pathlib import Path\n",
        "import requests \n",
        "\n",
        "# Setup path to data folder \n",
        "\n",
        "data_path = Path(\"data/\") # The trailing forward slash (/) in the string \n",
        "                          # is used to indicate that it represents a \n",
        "                          # directory rather than a specific file. \n",
        "                          # It's a common convention to include the trailing slash \n",
        "                          # in directory paths to differentiate them from file paths.\n",
        "\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\") \n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORGtSU9cyOFK",
        "outputId": "20c1a91b-0591-4f72-ee5b-6389f064607c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "fORSi7i10-RA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Creating Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "YbFUlonC1ObP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Creating a transform for torchvision.models (manual creation)"
      ],
      "metadata": {
        "id": "1p8QGw4Z1W0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** As of `torchvision` v0.13+, there's an update to how data transforms can be created using `torchvision.models`. I've called the previous method \"manual creation\" and the new method \"auto creation\". This notebook showcases both.\n",
        "\n",
        "When using a pretrained model, it's important that **your custom data going into the model is prepared in the same way as the original training data that went into the model**."
      ],
      "metadata": {
        "id": "wQmCS4sd6Duh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Question:** *Where did the mean and standard deviation values come from? Why do we need to do this?*\n",
        ">\n",
        "> These were calculated from the data. Specifically, the ImageNet dataset by taking the means and standard deviations across a subset of images.\n",
        ">\n",
        "> We also don't *need* to do this. Neural networks are usually quite capable of figuring out appropriate data distributions (they'll calculate where the mean and standard deviations need to be on their own) but setting them at the start can help our networks achieve better performance quicker."
      ],
      "metadata": {
        "id": "xCx3LQm87DJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prior to `torchvision` v0.13+, to create a transform for a pretrained model in `torchvision.models`, the documentation stated:\n",
        "\n",
        "> All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. \n",
        ">\n",
        "> The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]` and `std = [0.229, 0.224, 0.225]`. \n",
        ">\n",
        "> You can use the following transform to normalize:\n",
        ">\n",
        "> ```\n",
        "> normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        ">                                  std=[0.229, 0.224, 0.225])\n",
        "> ```\n"
      ],
      "metadata": {
        "id": "HLOuNWf48nJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually creating transform pipeline \n",
        "\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ],
      "metadata": {
        "id": "3mz592hm6DTo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Dataloaders\n",
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2prGjro-xd2",
        "outputId": "526d6ee4-ed2d-4274-bd41-a333b344ee11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f1e929275e0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f1e929276a0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2.2 Creating a transform for torchvision.models (auto creation)"
      ],
      "metadata": {
        "id": "9bgk6JbxAUZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "799_VeAUAtFj",
        "outputId": "8d4b6a62-1a33-4b34-8bd8-462076bf8b8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet_B0_Weights.IMAGENET1K_V1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DE2lewAA16k",
        "outputId": "40dfa129-9285-4a41-a9a1-11b4875abaec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BICUBIC\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=auto_transforms, # perform same data transforms on our own data as the pretrained model\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrGR9z4sBCiE",
        "outputId": "bd364667-1af0-40e1-d8fc-41bf4f36869a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f1e96eab610>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f1e92925f90>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Getting Pretrained Model"
      ],
      "metadata": {
        "id": "17vgJx2LBt-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Setting up a pretrained model\n",
        "\n",
        "The pretrained model we're going to be using is [`torchvision.models.efficientnet_b0()`](https://pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b0.html).\n",
        "\n",
        "The architecture is from the paper *[EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)*.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/06-effnet-b0-feature-extractor.png\" alt=\"efficienet_b0 from PyTorch torchvision feature extraction model\" width=900/>\n",
        "\n",
        "*Example of what we're going to create, a pretrained [`EfficientNet_B0` model](https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html) from `torchvision.models` with the output layer adjusted for our use case of classifying pizza, steak and sushi images.*\n",
        "\n",
        "We can setup the `EfficientNet_B0` pretrained ImageNet weights using the same code as we used to create the transforms."
      ],
      "metadata": {
        "id": "cNUZm2koM01S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights \n",
        "model1 = torchvision.models.efficientnet_b0(weights=weights).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWB5mr6kNwKC",
        "outputId": "f0eb48dd-2670-4e44-a8e3-9f7dcb510577"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 264MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8k0hWLrOaAD",
        "outputId": "cf860d6e-a616-465c-f8c7-7c5a33928dcc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=True)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we print the model, we get something similar to the following:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/06-v2-effnetb0-model-print-out.png\" alt=\"output of printing the efficientnet_b0 model from torchvision.models\" width=900/>"
      ],
      "metadata": {
        "id": "A_BVHQQsVIhx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}