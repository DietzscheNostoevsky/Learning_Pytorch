{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DietzscheNostoevsky/Learning_Pytorch/blob/main/05_Pytorch_Going_Modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee1q_1YynS72"
      },
      "source": [
        "# PyTorch Going Modular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V9ASvHsnS79"
      },
      "source": [
        "Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNzOBwXtnS7-"
      },
      "source": [
        "For example, we could turn our notebook code from a series of cells into the following Python files:\n",
        "\n",
        "* `data_setup.py` - a file to prepare and download data if needed.  \n",
        "* `engine.py` - a file containing various training functions.  \n",
        "* `model_builder.py` or model.py - a file to create a PyTorch model.  \n",
        "* `train.py` - a file to leverage all other files and train a target PyTorch model.\n",
        "* `utils.py` - a file dedicated to helpful utility functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWhIOW30nS7_"
      },
      "source": [
        "**Production code** is code that runs to offer a service to someone or something."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Data"
      ],
      "metadata": {
        "id": "IoMxFYhZnW-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to see what is inside the directory \n",
        "# using os.walk()\n",
        "import os\n",
        "\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "  \n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "vQSOh6dqrl9b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smaller Dataset"
      ],
      "metadata": {
        "id": "oRG9qhYMninv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "# Download pizza, steak, sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\") \n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "# Remove zip file\n",
        "os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCV1DVOlnee-",
        "outputId": "4d9ce508-71f8-47bb-ff6d-7a49b17fede1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists.\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n",
            "There are 2 directories and 0 images in 'data/pizza_steak_sushi'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'.\n",
            "There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'.\n",
            "There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'.\n",
            "There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'.\n",
            "There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'.\n",
            "There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'.\n",
            "There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Larger Dataset"
      ],
      "metadata": {
        "id": "_n3yChRQnoe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "\n",
        "# Mount the GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = Path(\"data/\")  # The trailing forward slash (/) in the string\n",
        "# is used to indicate that it represents a\n",
        "# directory rather than a specific file.\n",
        "# It's a common convention to include the trailing slash\n",
        "# in directory paths to differentiate them from file paths.\n",
        "\n",
        "image_path_full = data_path / \"pizza_steak_sushi_full\"\n",
        "\n",
        "if image_path_full.is_dir():\n",
        "    print(f\"{image_path_full} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path_full} directory, creating one...\")\n",
        "    image_path_full.mkdir(parents=True, exist_ok=True)\n",
        "zip_data = \"/content/drive/Othercomputers/My MacBook Air/GitHub/-Machine_Learning/Learning_Pytorch/pizza_steak_sushi_100_percent.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_data, \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path_full)\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir_full = image_path_full / \"train\"\n",
        "test_dir_full = image_path_full / \"test\"\n",
        "\n",
        "walk_through_dir(image_path_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf2Fs_c3ns11",
        "outputId": "04a150c7-03e6-40b7-cae4-d2dcf4fb1acc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "data/pizza_steak_sushi_full directory exists.\n",
            "Unzipping pizza, steak, sushi data...\n",
            "There are 2 directories and 0 images in 'data/pizza_steak_sushi_full'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi_full/train'.\n",
            "There are 0 directories and 750 images in 'data/pizza_steak_sushi_full/train/sushi'.\n",
            "There are 0 directories and 750 images in 'data/pizza_steak_sushi_full/train/steak'.\n",
            "There are 0 directories and 750 images in 'data/pizza_steak_sushi_full/train/pizza'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi_full/test'.\n",
            "There are 0 directories and 250 images in 'data/pizza_steak_sushi_full/test/sushi'.\n",
            "There are 0 directories and 250 images in 'data/pizza_steak_sushi_full/test/steak'.\n",
            "There are 0 directories and 250 images in 'data/pizza_steak_sushi_full/test/pizza'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Create Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "O_GADxioqJBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A PyTorch Dataset and a PyTorch DataLoader are two different components used in PyTorch for handling and preparing data for training or inference.\n",
        "\n",
        "1. PyTorch Dataset:\n",
        "A PyTorch Dataset is an abstract class that represents a dataset. It provides an interface to access and manipulate the data. To use a custom dataset, you need to subclass the `torch.utils.data.Dataset` class and implement the `__len__` and `__getitem__` methods. The `__len__` method returns the size of the dataset, and the `__getitem__` method is used to retrieve a specific data sample given its index. The Dataset class is responsible for loading and preprocessing the data, but it doesn't perform any data loading in parallel or handle batching.\n",
        "\n",
        "2. PyTorch DataLoader:\n",
        "A PyTorch DataLoader is an iterator that provides a convenient way to iterate over a dataset in mini-batches. It wraps a PyTorch Dataset and provides options for parallel data loading, shuffling, and batching. The DataLoader takes care of creating and managing multiple worker processes to load data in parallel, which can significantly speed up the data loading process. It automatically collates individual data samples into batches, allowing you to efficiently process mini-batches of data during training or inference. Additionally, the DataLoader can shuffle the data at the beginning of each epoch to introduce randomness and prevent any bias during training.\n",
        "\n",
        "In summary, a PyTorch Dataset is responsible for accessing and preprocessing the data, while a PyTorch DataLoader takes care of parallel data loading, batching, and shuffling. Together, they provide a convenient and efficient way to handle and process large datasets in PyTorch."
      ],
      "metadata": {
        "id": "SRCgZ1Smur0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting train and test directory \n",
        "\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "# Change here to use full dataset \n",
        "\n",
        "#train_dir = image_path_full / \"train\"\n",
        "#test_dir = image_path_full / \"test\""
      ],
      "metadata": {
        "id": "pHhFL6QGsM42"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Create simple transform\n",
        "data_transform = transforms.Compose([ \n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Use ImageFolder to create dataset(s)\n",
        "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir, \n",
        "                                 transform=data_transform)\n",
        "\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqnNmNA4qIs4",
        "outputId": "de7c0613-6cbb-4da3-b4fc-cc1d39d2ada3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data:\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 225\n",
            "    Root location: data/pizza_steak_sushi/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "           )\n",
            "Test data:\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 75\n",
            "    Root location: data/pizza_steak_sushi/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test Datasets into DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data, \n",
        "                              batch_size=1, # how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
        "                              shuffle=True) # shuffle the data?\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data, \n",
        "                             batch_size=1, \n",
        "                             num_workers=1, \n",
        "                             shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "N4iW6Qs7vwJp",
        "outputId": "028861f3-0882-4d6d-db41-313391cf30fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7fab137fa860>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7fab137f8fd0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}